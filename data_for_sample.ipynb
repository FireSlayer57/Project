{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikhail\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:69: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from scipy import optimize\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Generating pairwise correlations of 10 sectors\n",
    "M2_S = np.zeros((10,10))\n",
    "for i,j in product (range(0,10),range(0,10)):\n",
    "    if (i==j):\n",
    "        M2_S[i][j] = 1.0\n",
    "    else:\n",
    "        if (i>j):\n",
    "            M2_S[i][j] = rd.uniform(-1.0,1.0)\n",
    "            M2_S[j][i] = M2_S[i][j]   \n",
    "\n",
    "\n",
    "#Correlation matrix of 100 stocks based on their sector structure\n",
    "\n",
    "def tanh(x):\n",
    "    for (k,i,j) in product(range(0,61), range(0,95), range(0,95)):\n",
    "        x[k][i][j] = np.tanh(x[k][i][j])\n",
    "\n",
    "\n",
    "def daily_correlation(sigma):\n",
    "    daily_corr = np.zeros((61, 95, 95))\n",
    "    for (i, j) in product (range(0,95), range(0,95)):\n",
    "        if (i>j):\n",
    "            daily_corr[0][i][j] = np.random.normal(M2_S[i/10][j/10], sigma, 1)\n",
    "            daily_corr[0][j][i] = daily_corr[0][i][j]\n",
    "        else:\n",
    "            if (i==j):\n",
    "                daily_corr[0][i][j] = 1.0\n",
    "        for k in range(1, 61):\n",
    "            if (i>j):\n",
    "                daily_corr[k][i][j] = np.random.normal(daily_corr[k-1][i][j], sigma, 1)\n",
    "                daily_corr[k][j][i] = daily_corr[k][i][j]\n",
    "            else:\n",
    "                if (i==j):\n",
    "                    daily_corr[k][i][j] = 1.0  \n",
    "    tanh(daily_corr)\n",
    "    return daily_corr\n",
    "\n",
    "daily_corr = daily_correlation(0.1)\n",
    "\n",
    "\n",
    "#Plots showing evolution of the correlations between some stocks\n",
    "def plots(daily_corr):       \n",
    "    a,b,c,d = [],[],[],[]\n",
    "    for i in range (0,61):\n",
    "        a.append(daily_corr[i][9][94])\n",
    "        b.append(daily_corr[i][93][94])\n",
    "        c.append(daily_corr[i][10][11])\n",
    "        d.append(daily_corr[i][10][12])\n",
    "\n",
    "    plt.plot(a, 'r', b, 'b', c, 'g', d, 'c')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#Generating samples of stock returns based on their correlations over 61 days\n",
    "def return_generator(N_samples, daily_corr):\n",
    "    mu = np.zeros(95)\n",
    "    returns = []\n",
    "    for k in range(0,61):\n",
    "        returns.append(np.random.multivariate_normal(mu, daily_corr[k], N_samples))\n",
    "    last_returns = returns[60]\n",
    "    returns = np.swapaxes(np.delete(returns, 60, axis=0), 0, 1)\n",
    "    return returns, last_returns\n",
    "\n",
    "\n",
    "#Empirical models for correlation matrices of stock returns constructed from 60 days\n",
    "#model1 - straight-forward empirical\n",
    "#model2 - with respect to the knowledge of underlying sector structure\n",
    "#r1 - sample returns on the 61st day\n",
    "def empiric_models(N_samples, daily_corr):\n",
    "    r0, r1 = return_generator(N_samples, daily_corr)\n",
    "    model1 = []\n",
    "    model2 = np.zeros((N_samples, 95, 95))\n",
    "    sector_average_corr = np.zeros((N_samples, 10, 10))\n",
    "    for k in range(0, N_samples):\n",
    "        model1.append(np.corrcoef(r0[k].transpose()))\n",
    "        for (i,j) in product(range(0,9), range(0,9)):         \n",
    "            if (i>j):\n",
    "                sector_average_corr[k][i][j] = np.mean(model1[k][i*10:(i+1)*10, j*10:(j+1)*10])\n",
    "                sector_average_corr[k][j][i] = sector_average_corr[k][i][j]\n",
    "            else:\n",
    "                if (i==j):\n",
    "                    sector_average_corr[k][i][j] = (np.sum(model1[k][i*10:(i+1)*10, j*10:(j+1)*10])-10)/90\n",
    "        for i in range(0,9):\n",
    "            sector_average_corr[k][i][9] = np.mean(model1[k][i*10:(i+1)*10, 90:95])\n",
    "            sector_average_corr[k][9][i] = sector_average_corr[k][i][9]\n",
    "        sector_average_corr[k][9][9] = (np.sum(model1[k][90:95, 90:95])-5)/20\n",
    "        for (i,j) in product(range(0,95), range(0,95)):\n",
    "            if (i==j):\n",
    "                model2[k][i][j] = 1.0\n",
    "            else:\n",
    "                model2[k][i][j] = sector_average_corr[k][i/10][j/10]\n",
    "    return model1, model2, r1\n",
    "    \n",
    "    \n",
    "    \n",
    "#Weights for standard minimum variance Markowitz portfolio\n",
    "bnds = []\n",
    "for i in range(0,95):\n",
    "    bnds.append((0, None))\n",
    "bnds = tuple(bnds)\n",
    "cons_sum = ({'type': 'eq', 'fun': lambda x: np.sum(x)-1})\n",
    "def portfolio_variance(x, matrix):\n",
    "    p_var = np.dot(np.dot(x, matrix), x)\n",
    "    return p_var\n",
    "def grad_portfolio_var(x, matrix):\n",
    "    grad = []\n",
    "    for i in range(0,95):\n",
    "        s = 2*np.dot(matrix[i], x)\n",
    "        grad.append(s)\n",
    "    return grad\n",
    "def weights(matrix, number_of_weights):\n",
    "    x0 = (1./number_of_weights)*np.ones(number_of_weights)\n",
    "    res = optimize.minimize(portfolio_variance, x0, args=(matrix), method = 'SLSQP',\n",
    "                            jac = grad_portfolio_var, bounds=bnds, constraints=cons_sum,\n",
    "                            options={'maxiter': 100})\n",
    "    return res.x\n",
    "\n",
    "\n",
    "#Error function for sample/out_of_sample as variance of optimal portfolio returns\n",
    "#range_of_sample - range on which we estimate optimal weights\n",
    "#out_of_sample range is set to be 200\n",
    "m2 = np.identity(95)\n",
    "def error(x, sample_or_not, range_of_sample, m0, m1, r1):\n",
    "    if (sample_or_not=='sample'):\n",
    "        boundary0 = 0\n",
    "        boundary1 = range_of_sample\n",
    "    if (sample_or_not=='out_of_sample'):\n",
    "        boundary0 = N_samples - range_of_sample\n",
    "        boundary1 = N_samples\n",
    "    portfolio_returns = []\n",
    "    for k in range (boundary0, boundary1):\n",
    "        m = x[0]*m0[k] + x[1]*m1[k] + (1-x[0]-x[1])*m2\n",
    "        w = weights(m, 95)\n",
    "        portfolio_returns.append(np.dot(w, r1[k]))\n",
    "    return np.var(portfolio_returns)\n",
    "\n",
    "\n",
    "#Optimizing model weights with positivity constraints \n",
    "#Function depending on the range_of_sample\n",
    "cons = ({'type': 'ineq', 'fun': lambda x: x[0]},\n",
    "       {'type': 'ineq', 'fun': lambda x: x[1]},\n",
    "       {'type': 'ineq', 'fun': lambda x: 1-x[0]-x[1]})\n",
    "def optimal_model_weights(a, m0, m1, r1):\n",
    "    x0 = [0.5, 0.3]\n",
    "    start_time = datetime.datetime.now()\n",
    "    res = optimize.minimize(error, x0, args=('sample', a, m0, m1, r1), method='COBYLA',\n",
    "                       constraints=cons,\n",
    "                       options={'maxiter': 100})\n",
    "    return datetime.datetime.now() - start_time, res.x, res.fun\n",
    "\n",
    "def two_D_m0(m0_all):\n",
    "    b = np.zeros((len(m0_all), 95*95))\n",
    "    for (k, i, j) in product(range(0, len(m0_all)), range(0, 95), range(0, 95)):\n",
    "        b[k][i*95+j] = m0_all[k][i][j]\n",
    "    return b\n",
    "\n",
    "def two_D_m1(m1_all):\n",
    "    b = np.zeros((len(m1_all), 95*95))\n",
    "    for (k, i, j) in product(range(0, len(m1_all)), range(0, 95), range(0, 95)):\n",
    "        b[k][i*95+j] = m1_all[k][i][j]\n",
    "    return b\n",
    "\n",
    "sigma_values = np.sort(np.random.uniform(0.05, 0.3, 100))\n",
    "sigmas = pd.DataFrame(sigma_values, index=None, columns=None)\n",
    "sigmas.to_csv('sigmas.csv', header=None)\n",
    "I = [20., 27., 34., 40., 46., 52., 59., 66., 73., 79.]\n",
    "def data_for_stump(sigma_values, samples_per_stump):\n",
    "    daily_corr = daily_correlation(sigma_values[0])\n",
    "    m0_all, m1_all, r1_all = empiric_models(samples_per_stump, daily_corr)\n",
    "    for i in range(1,100):\n",
    "        daily_corr = daily_correlation(sigma_values[i])\n",
    "        m0_upd, m1_upd, r1_upd = empiric_models(samples_per_stump, daily_corr)\n",
    "        m0_all = np.concatenate((m0_all, m0_upd), 0)\n",
    "        m1_all = np.concatenate((m1_all, m1_upd), 0)\n",
    "        r1_all = np.concatenate((r1_all, r1_upd), 0)\n",
    "    m0_all = two_D_m0(m0_all)\n",
    "    m1_all = two_D_m1(m1_all)\n",
    "    pd.DataFrame(m0_all).to_csv('m0_all.csv', header=None)\n",
    "    pd.DataFrame(m1_all).to_csv('m1_all.csv', header=None)\n",
    "    pd.DataFrame(r1_all).to_csv('r1_all.csv', header=None)\n",
    "    \n",
    "data_for_stump(sigma_values, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
